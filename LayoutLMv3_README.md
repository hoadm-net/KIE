# LayoutLMv3 for Document Understanding - Token Classification

## üìã T·ªïng quan

Pipeline ho√†n ch·ªânh ƒë·ªÉ fine-tune v√† s·ª≠ d·ª•ng **LayoutLMv3** (Microsoft) cho b√†i to√°n **token classification** tr√™n documents (form understanding, information extraction).

### Ki·∫øn tr√∫c Model

**LayoutLMv3** l√† multimodal transformer k·∫øt h·ª£p 3 modalities:
- **Text**: Tokenization v·ªõi RoBERTa tokenizer (Byte-level BPE)
- **Layout**: Bounding box coordinates (normalized 0-1000)
- **Image**: Patch embeddings t·ª´ document image

```
Input: Image + Words + Bounding Boxes
         ‚Üì
LayoutLMv3 Encoder (Text + Layout + Vision)
         ‚Üì
Token Classification Head
         ‚Üì
Output: BIO Tags (B-QUESTION, I-ANSWER, B-HEADER, ...)
```

**Key Features:**
- Pre-trained tr√™n 11M document images
- Unified text-image masking
- Word-patch alignment objective
- State-of-the-art tr√™n FUNSD, CORD, SROIE

---

## üéØ B√†i to√°n: Token Classification tr√™n Forms

### Task Definition
G√°n nh√£n cho **m·ªói word** trong document v·ªõi BIO tagging scheme:

| Label | Meaning | Example |
|-------|---------|---------|
| B-QUESTION | Begin-Question | "Name:", "Date:", "Address:" |
| I-QUESTION | Inside-Question | "full", "name" trong "Full Name:" |
| B-ANSWER | Begin-Answer | "John" trong answer field |
| I-ANSWER | Inside-Answer | "Smith" trong "John Smith" |
| B-HEADER | Begin-Header | "Application", "Form" |
| I-HEADER | Inside-Header | "Number" trong "Application Number" |
| B-OTHER | Begin-Other | Metadata, page numbers |
| I-OTHER | Inside-Other | Continuation c·ªßa OTHER |
| O | Outside | Background, kh√¥ng thu·ªôc entity |

### ·ª®ng d·ª•ng
- **Form Understanding**: Tr√≠ch xu·∫•t th√¥ng tin t·ª´ forms, invoices, receipts
- **Document Parsing**: Ph√¢n lo·∫°i c√°c ph·∫ßn trong document
- **Information Extraction**: T·ª± ƒë·ªông ƒëi·ªÅn database t·ª´ scanned documents

---

## üìÅ Dataset: FUNSD (Form Understanding in Noisy Scanned Documents)

### Th√¥ng tin Dataset
- **Train**: 149 annotated forms
- **Test**: 50 annotated forms
- **Total words**: ~30,000 words v·ªõi BIO labels
- **Ngu·ªìn**: RVL-CDIP dataset (scanned documents)

### C·∫•u tr√∫c Annotation
```json
{
  "form": [
    {
      "id": 0,
      "label": "question",  // entity-level label
      "box": [x0, y0, x1, y1],
      "words": [
        {
          "text": "Full",
          "box": [x0, y0, x1, y1]
        },
        {
          "text": "Name:",
          "box": [x0, y0, x1, y1]
        }
      ]
    }
  ]
}
```

### X·ª≠ l√Ω ƒê·∫∑c bi·ªát
1. **Empty Words Filtering**: Lo·∫°i b·ªè words r·ªóng ho·∫∑c ch·ªâ ch·ª©a whitespace
2. **Box Normalization**: Normalize t·ªça ƒë·ªô v·ªÅ scale 0-1000
3. **BIO Conversion**: Convert entity labels sang token-level BIO tags

---

## üîß Pipeline Components

### 1. Preprocessing (`preprocess_funsd.py`)
**FUNSDDataset class** - Load v√† preprocess data cho training

**Key Functions:**
- `convert_to_bio_labels()`: Convert entity labels ‚Üí BIO tags
- `normalize_box()`: Normalize bounding boxes to 0-1000 scale
- `__getitem__()`: Return processed sample v·ªõi processor alignment

**Critical Implementation:**
```python
# Filter empty words (MUST match training & inference!)
if not word_text or not word_text.strip():
    continue

# Use processor with word_labels for automatic alignment
encoding = processor(
    image, 
    words, 
    boxes=boxes, 
    word_labels=word_labels,  # Processor auto-aligns labels to tokens
    padding="max_length",
    truncation=True
)
```

**Processor Behavior:**
- Tokenizes words into subword tokens (BPE)
- **only_label_first_subword=True**: Ch·ªâ first token nh·∫≠n label
- Remaining subword tokens ‚Üí label = -100 (ignored in loss)

---

### 2. Training (`train_layoutlmv3.py`)
**LayoutLMv3Trainer class** - Fine-tune model tr√™n FUNSD

**Hyperparameters (recommended):**
```python
learning_rate = 5e-5
num_epochs = 20
batch_size = 2
warmup_ratio = 0.1
gradient_accumulation_steps = 4
```

**Training Process:**
1. Load pre-trained `microsoft/layoutlmv3-base`
2. Initialize token classification head (9 classes)
3. AdamW optimizer v·ªõi linear warmup schedule
4. Mixed precision training (FP16)
5. Best model checkpoint based on eval F1

**Usage:**
```bash
python train_layoutlmv3.py \
  --data_dir data/FUNSD \
  --output_dir outputs/experiment_name \
  --num_epochs 20 \
  --batch_size 2 \
  --learning_rate 5e-5
```

**Expected Results (20 epochs):**
- F1 Score: ~0.85-0.90
- Accuracy: ~88-92%
- Training time: ~2-3 hours on single GPU

---

### 3. Evaluation (`evaluate_layoutlmv3.py`)
**LayoutLMv3Evaluator class** - ƒê√°nh gi√° model tr√™n test set

**Metrics:**
- **Accuracy**: Token-level accuracy
- **Precision/Recall/F1**: Per-class v√† macro average
- **Confusion Matrix**: Visualization of class predictions
- **Classification Report**: Detailed per-class metrics

**Usage:**
```bash
python evaluate_layoutlmv3.py \
  --model_path outputs/experiment/best_model \
  --data_dir data/FUNSD \
  --output_dir outputs/evaluation
```

**Outputs:**
- `confusion_matrix.png`: Visual confusion matrix
- `classification_report.txt`: Detailed metrics
- `evaluation_results.json`: Machine-readable results

---

### 4. Inference (`inference_layoutlmv3.py`)
**LayoutLMv3Predictor class** - Predict labels tr√™n documents m·ªõi

**Key Implementation - Approach 2 (Dummy Labels):**
```python
# CRITICAL: Use dummy labels ƒë·ªÉ processor align gi·ªëng training!
dummy_labels = [0] * len(words)

encoding = processor(
    image,
    words,
    boxes=boxes,
    word_labels=dummy_labels,  # Dummy ƒë·ªÉ c√≥ alignment info
    padding="max_length",
    truncation=True
)

# Extract predictions from positions where label != -100
predictions = model(**encoding).logits.argmax(-1)
label_positions = encoding['labels']  # Processor ƒë√£ align!

word_predictions = []
for i, label_val in enumerate(label_positions):
    if label_val != -100:  # First token c·ªßa m·ªôt word
        word_predictions.append(id2label[predictions[i]])
```

**T·∫°i sao d√πng Approach 2:**
1. **Consistency**: Training v√† inference d√πng C√ôNG alignment logic
2. **Automatic Handling**: Processor t·ª± ƒë·ªông x·ª≠ l√Ω subword tokenization
3. **Edge Cases**: Empty words, special chars, Unicode ƒë·ªÅu handle ƒë√∫ng
4. **Ti·∫øng Vi·ªát Ready**: Tokenization consistent cho d·∫•u v√† k√Ω t·ª± ƒë·∫∑c bi·ªát

**Usage:**
```bash
python inference_layoutlmv3.py \
  --model_path outputs/experiment/best_model \
  --image_path data/test_image.png \
  --annotation_path data/test_annotation.json \
  --output_dir predictions
```

**Outputs:**
- `{image_name}_prediction.png`: Visualization v·ªõi bounding boxes
- `{image_name}_predictions.json`: Machine-readable predictions

---

## üáªüá≥ T∆∞∆°ng lai: Dataset Ti·∫øng Vi·ªát

### Challenges v·ªõi Ti·∫øng Vi·ªát

#### 1. Tokenization Issues
**V·∫•n ƒë·ªÅ:** RoBERTa tokenizer (trained on English) kh√¥ng t·ªëi ∆∞u cho ti·∫øng Vi·ªát

**Example:**
```python
# Word ti·∫øng Vi·ªát
word = "ƒë·∫≠u ph·ªông"

# RoBERTa BPE tokenization (BAD)
tokens = ["√Ñ", "##√°", "##¬∫", "##u", " ", "ph", "√°", "##¬ª", "##¬£", "ng"]
# ‚Üí 10 tokens cho 2 words! D·∫•u b·ªã split th√†nh bytes
```

**Impacts:**
- Alignment ph·ª©c t·∫°p h∆°n
- Nhi·ªÅu subword tokens ‚Üí exceed max_length d·ªÖ h∆°n
- Model kh√≥ h·ªçc patterns v·ªõi rare byte sequences

#### 2. Word Boundary Ambiguity
Ti·∫øng Vi·ªát kh√¥ng c√≥ spaces gi·ªØa syllables trong compound words:
- "ƒë·∫≠u ph·ªông" (2 words) vs "ƒë·∫≠u_ph·ªông" (1 compound)
- "h∆∞·ªõng d∆∞∆°ng" (2 words) vs "h∆∞·ªõng_d∆∞∆°ng" (sunflower - 1 concept)

---

### Gi·∫£i ph√°p ƒë·ªÅ xu·∫•t

#### Option 1: Fine-tune Tokenizer (Khuy·∫øn ngh·ªã)
**C√°ch l√†m:**
1. Thu th·∫≠p Vietnamese corpus (10M+ sentences)
2. Train custom BPE tokenizer:
```python
from tokenizers import ByteLevelBPETokenizer

tokenizer = ByteLevelBPETokenizer()
tokenizer.train(
    files=["vietnamese_corpus.txt"],
    vocab_size=50000,
    min_frequency=2,
    special_tokens=["<s>", "</s>", "<pad>", "<unk>", "<mask>"]
)

# Replace trong LayoutLMv3Processor
processor.tokenizer = LayoutLMv3TokenizerFast(tokenizer_object=tokenizer.tokenizer)
```

**Advantages:**
- T·ªëi ∆∞u cho Vietnamese text patterns
- Gi·∫£m s·ªë l∆∞·ª£ng subword tokens
- D·∫•u v√† k√Ω t·ª± ƒë·∫∑c bi·ªát ƒë∆∞·ª£c handle t·ªët h∆°n

**Training time:** ~2-4 hours on CPU

---

#### Option 2: Use LayoutXLM (Khuy·∫øn ngh·ªã cho production)
**LayoutXLM** = LayoutLMv3 architecture + **XLM-RoBERTa tokenizer**

**Advantages:**
- XLM-RoBERTa trained tr√™n 100 languages (including Vietnamese!)
- Multilingual support out-of-the-box
- Better tokenization cho ti·∫øng Vi·ªát

**C√°ch s·ª≠ d·ª•ng:**
```python
from transformers import LayoutXLMProcessor, LayoutXLMForTokenClassification

processor = LayoutXLMProcessor.from_pretrained("microsoft/layoutxlm-base")
model = LayoutXLMForTokenClassification.from_pretrained(
    "microsoft/layoutxlm-base",
    num_labels=9  # Your BIO tags
)

# Everything else gi·ªëng LayoutLMv3!
```

**Note:** LayoutXLM c√≥ architecture gi·ªëng LayoutLMv3 nh∆∞ng:
- Larger model (278M params vs 133M)
- Slower inference (~1.5x)
- Better multilingual performance

---

#### Option 3: Pre-tokenize v·ªõi Vietnamese Word Segmentation
**C√°ch l√†m:**
1. Use `underthesea` ho·∫∑c `pyvi` ƒë·ªÉ word segmentation:
```python
from underthesea import word_tokenize

text = "ƒë·∫≠u ph·ªông h·∫°t h∆∞·ªõng d∆∞∆°ng"
words = word_tokenize(text)
# ‚Üí ["ƒë·∫≠u_ph·ªông", "h·∫°t", "h∆∞·ªõng_d∆∞∆°ng"]
```

2. Treat compound words as single tokens trong annotation
3. M·ªói word = 1 label trong BIO scheme

**Advantages:**
- Control word boundaries explicitly
- Easier annotation
- More interpretable results

**Disadvantages:**
- Requires pre-processing step
- Word segmentation errors propagate

---

### Data Annotation Guide cho Ti·∫øng Vi·ªát

#### Format gi·ªëng FUNSD
```json
{
  "form": [
    {
      "label": "question",
      "words": [
        {"text": "H·ªç", "box": [x0, y0, x1, y1]},
        {"text": "v√†", "box": [x0, y0, x1, y1]},
        {"text": "t√™n:", "box": [x0, y0, x1, y1]}
      ]
    },
    {
      "label": "answer",
      "words": [
        {"text": "Nguy·ªÖn", "box": [x0, y0, x1, y1]},
        {"text": "VƒÉn", "box": [x0, y0, x1, y1]},
        {"text": "A", "box": [x0, y0, x1, y1]}
      ]
    }
  ]
}
```

#### Annotation Best Practices
1. **Consistency**: Quy·∫øt ƒë·ªãnh word boundary rules (compound words)
2. **OCR Integration**: S·ª≠ d·ª•ng VietOCR ho·∫∑c similar cho text extraction
3. **Box Accuracy**: Bounding boxes ch√≠nh x√°c quan tr·ªçng cho layout features
4. **Entity Granularity**: Quy·∫øt ƒë·ªãnh entity types ph√π h·ª£p v·ªõi domain

#### Sample Entity Types cho Vietnamese Forms
- `B-HO_TEN / I-HO_TEN`: H·ªç v√† t√™n
- `B-NGAY_SINH / I-NGAY_SINH`: Ng√†y sinh
- `B-DIA_CHI / I-DIA_CHI`: ƒê·ªãa ch·ªâ
- `B-SO_DIEN_THOAI / I-SO_DIEN_THOAI`: S·ªë ƒëi·ªán tho·∫°i
- `B-SO_CMND / I-SO_CMND`: S·ªë CMND/CCCD
- `B-NOI_CAP / I-NOI_CAP`: N∆°i c·∫•p
- `B-NGAY_CAP / I-NGAY_CAP`: Ng√†y c·∫•p

---

## üìä Performance Benchmarks

### FUNSD Dataset (English)

| Model | Epochs | F1 Score | Accuracy | Training Time |
|-------|--------|----------|----------|---------------|
| LayoutLMv3 (paper) | - | 90.59% | - | - |
| Our implementation | 1 | 58.6% | 74% | ~10 min |
| Our implementation | 20 | ~85-90% | ~88-92% | ~2-3 hours |

### Per-Class Performance (1 epoch)

| Label | Precision | Recall | F1 | Support |
|-------|-----------|--------|----|---------|
| B-QUESTION | 0.80 | 0.83 | 0.81 | 1046 |
| I-QUESTION | 0.82 | 0.59 | 0.68 | 1426 |
| B-ANSWER | 0.75 | 0.86 | 0.80 | 803 |
| I-ANSWER | 0.73 | 0.84 | 0.78 | 2476 |
| **B-HEADER** | 0.64 | 0.29 | **0.40** | 119 ‚ö†Ô∏è |
| I-HEADER | 0.80 | 0.44 | 0.57 | 255 |
| **B-OTHER** | 0.88 | 0.35 | **0.51** | 257 ‚ö†Ô∏è |
| I-OTHER | 0.69 | 0.76 | 0.72 | 1974 |

**Notes:**
- HEADER v√† OTHER classes c√≥ √≠t data ‚Üí performance th·∫•p h∆°n
- C·∫ßn augmentation ho·∫∑c class weighting ƒë·ªÉ improve
- 20 epochs s·∫Ω improve ƒë√°ng k·ªÉ

---

## üöÄ Quick Start

### 1. Setup Environment
```bash
# Clone repo
git clone <your-repo>
cd KIE

# Install dependencies
pip install -r requirements.txt

# Download FUNSD dataset
python funsd_download.py
```

### 2. Train Model
```bash
# Quick test (1 epoch)
python train_layoutlmv3.py \
  --data_dir data/FUNSD \
  --output_dir outputs/test \
  --num_epochs 1 \
  --batch_size 2

# Full training (20 epochs)
python train_layoutlmv3.py \
  --data_dir data/FUNSD \
  --output_dir outputs/full_training \
  --num_epochs 20 \
  --batch_size 2 \
  --learning_rate 5e-5
```

### 3. Evaluate
```bash
python evaluate_layoutlmv3.py \
  --model_path outputs/full_training/run_*/best_model \
  --data_dir data/FUNSD \
  --output_dir outputs/evaluation
```

### 4. Inference
```bash
python inference_layoutlmv3.py \
  --model_path outputs/full_training/run_*/best_model \
  --image_path data/FUNSD/testing_data/images/example.png \
  --annotation_path data/FUNSD/testing_data/annotations/example.json \
  --output_dir predictions
```

---

## üîç Troubleshooting

### Common Issues

#### 1. CUDA Out of Memory
**Solution:**
```bash
# Gi·∫£m batch size
python train_layoutlmv3.py --batch_size 1 --gradient_accumulation_steps 8

# Ho·∫∑c reduce max_length
python train_layoutlmv3.py --max_length 256
```

#### 2. Low Accuracy on Inference
**Checklist:**
- ‚úÖ Empty words ƒë∆∞·ª£c filter ·ªü c·∫£ training v√† inference
- ‚úÖ Box normalization consistent (0-1000 scale)
- ‚úÖ D√πng dummy labels trong inference (Approach 2)
- ‚úÖ Eval accuracy c√≥ consistent v·ªõi inference kh√¥ng

#### 3. Class Imbalance
**Solution:**
```python
# S·ª≠ d·ª•ng class weights trong loss
from torch.nn import CrossEntropyLoss

class_weights = torch.tensor([0.5, 2.0, 2.0, 1.0, 1.0, 3.0, 3.0, 2.0, 2.0])
loss_fct = CrossEntropyLoss(weight=class_weights)
```

---

## üìö References

1. **LayoutLMv3 Paper**: [LayoutLMv3: Pre-training for Document AI with Unified Text and Image Masking](https://arxiv.org/abs/2204.08387)
2. **FUNSD Dataset**: [Form Understanding in Noisy Scanned Documents](https://guillaumejaume.github.io/FUNSD/)
3. **Hugging Face Docs**: [LayoutLMv3 Documentation](https://huggingface.co/docs/transformers/model_doc/layoutlmv3)
4. **LayoutXLM**: [Multimodal Pre-training for Multilingual Document Understanding](https://arxiv.org/abs/2104.08836)

---

## üìù License & Citation

```bibtex
@article{huang2022layoutlmv3,
  title={LayoutLMv3: Pre-training for Document AI with Unified Text and Image Masking},
  author={Huang, Yupan and Lv, Tengchao and Cui, Lei and Lu, Yutong and Wei, Furu},
  journal={arXiv preprint arXiv:2204.08387},
  year={2022}
}
```

---

## üë• Contact & Contribution

For questions, issues, or contributions, please open an issue on GitHub.

**Maintained by**: [Your Name]  
**Last Updated**: February 2026
